{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2db509c1-9d91-4efe-85d2-497f2ca3e5e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of measurements: 2\n",
      "event000000001-measurements.dat saved to measurements.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laiji\\AppData\\Local\\Temp\\ipykernel_26392\\389046238.py:62: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(new_data, ignore_index=True)\n",
      "C:\\Users\\laiji\\AppData\\Local\\Temp\\ipykernel_26392\\389046238.py:62: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(new_data, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import struct\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def read_binary_data(binary_file, start_offset, ele_offsets):\n",
    "    \"\"\"\n",
    "    Reads and parses binary data from a file into a DataFrame.\n",
    "    \n",
    "     - Number of measurement (size of the dump) found in 0-7 (unsigned long long) \n",
    "     - local0 found in 8-11 (float)\n",
    "     - local1 found in 12-15 (float)\n",
    "     - var_local0 found in offset 16-19 (float)\n",
    "     - var_local1 found in offset 20-23 (float)\n",
    "     - geometry ID found in offset 24-31 (unsigned long long)\n",
    "     - measurement_id found in offset 32-39 (unsigned long long)\n",
    "     - cluster_link found in offset 40-47 (unsigned long long)\n",
    "     - meas_dim found in offset 48-51 (unsigned int)\n",
    "\n",
    "    Args:\n",
    "        binary_file (str): Path to the binary file.\n",
    "        start_offset (int): Offset to start reading from.\n",
    "        ele_offsets (list): Byte offsets for unpacking.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the parsed data.\n",
    "    \"\"\"\n",
    "    # Define an empty DataFrame with the desired columns\n",
    "    df = pd.DataFrame(columns=[\n",
    "        \"local0\", \"local1\", \"var_local0\", \"var_local1\",\n",
    "        \"geometry_id\", \"measurement_id\", \"cluster_link\", \"meas_dim\"\n",
    "    ])\n",
    "\n",
    "    # Get the total file size\n",
    "    file_size = os.path.getsize(binary_file)\n",
    "\n",
    "    # Read the binary data\n",
    "    with open(binary_file, \"rb\") as bin_file:\n",
    "        # mm = \n",
    "        print(\"number of measurements:\", struct.unpack(\"Q\", bin_file.read(8))[0])\n",
    "        \n",
    "        bin_file.seek(start_offset)\n",
    "        raw_bytes = bin_file.read(file_size - start_offset)\n",
    "\n",
    "\n",
    "    # Ensure offsets are consistent\n",
    "    if len(ele_offsets) < 9:\n",
    "        raise ValueError(\"ele_offsets must contain at least 9 elements for parsing.\")\n",
    "\n",
    "    # Process the binary data\n",
    "    for i in range(0, len(raw_bytes), ele_offsets[-1]):\n",
    "        try:\n",
    "            new_data = {\n",
    "                \"local0\": struct.unpack(\"f\", raw_bytes[i + ele_offsets[0]: i + ele_offsets[1]])[0],\n",
    "                \"local1\": struct.unpack(\"f\", raw_bytes[i + ele_offsets[1]: i + ele_offsets[2]])[0],\n",
    "                \"var_local0\": struct.unpack(\"f\", raw_bytes[i + ele_offsets[2]: i + ele_offsets[3]])[0],\n",
    "                \"var_local1\": struct.unpack(\"f\", raw_bytes[i + ele_offsets[3]: i + ele_offsets[4]])[0],\n",
    "                \"geometry_id\": struct.unpack(\"Q\", raw_bytes[i + ele_offsets[4]: i + ele_offsets[5]])[0],\n",
    "                \"measurement_id\": struct.unpack(\"Q\", raw_bytes[i + ele_offsets[5]: i + ele_offsets[6]])[0],\n",
    "                \"cluster_link\": struct.unpack(\"Q\", raw_bytes[i + ele_offsets[6]: i + ele_offsets[7]])[0],\n",
    "                \"meas_dim\": struct.unpack(\"I\", raw_bytes[i + ele_offsets[7]: i + ele_offsets[8]])[0],\n",
    "            }\n",
    "            df = df.append(new_data, ignore_index=True)\n",
    "        except struct.error:\n",
    "            # Stop processing if there are not enough bytes left\n",
    "            break\n",
    "\n",
    "    return df\n",
    "\n",
    "# Configuration\n",
    "binary_file = \"event000000001-measurements.dat\"\n",
    "start_offset = 8\n",
    "ele_offsets = [0, 4, 8, 12, 16, 24, 32, 40, 44, 64]\n",
    "\n",
    "# Read the binary data into a DataFrame\n",
    "df = read_binary_data(binary_file, start_offset, ele_offsets)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_file = \"measurements.csv\"\n",
    "df.to_csv(csv_file, index=False)\n",
    "\n",
    "print(f\"{binary_file} saved to {csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b4890d57-f494-4dcc-b902-6b19fb6812e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of measurements: 2\n",
      "event000000001-measurements.dat saved to measurements.csv\n"
     ]
    }
   ],
   "source": [
    "import struct\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def read_binary_data(binary_file, start_offset, ele_offsets):\n",
    "    \"\"\"\n",
    "    Reads and parses binary data from a file into a DataFrame.\n",
    "    \n",
    "     - Number of measurement (size of the dump) found in 0-7 (unsigned long long) \n",
    "     - local0 found in 8-11 (float)\n",
    "     - local1 found in 12-15 (float)\n",
    "     - var_local0 found in offset 16-19 (float)\n",
    "     - var_local1 found in offset 20-23 (float)\n",
    "     - geometry ID found in offset 24-31 (unsigned long long)\n",
    "     - measurement_id found in offset 32-39 (unsigned long long)\n",
    "     - cluster_link found in offset 40-47 (unsigned long long)\n",
    "     - meas_dim found in offset 48-51 (unsigned int)\n",
    "\n",
    "    Args:\n",
    "        binary_file (str): Path to the binary file.\n",
    "        start_offset (int): Offset to start reading from.\n",
    "        ele_offsets (list): Byte offsets for unpacking.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the parsed data.\n",
    "    \"\"\"\n",
    "    # Define an empty DataFrame \n",
    "    data = []\n",
    "\n",
    "    # Get the total file size\n",
    "    file_size = os.path.getsize(binary_file)\n",
    "\n",
    "    # Read the binary data\n",
    "    with open(binary_file, \"rb\") as bin_file:\n",
    "        # mm = \n",
    "        print(\"number of measurements:\", struct.unpack(\"Q\", bin_file.read(8))[0])\n",
    "        \n",
    "        bin_file.seek(start_offset)\n",
    "        raw_bytes = bin_file.read(file_size - start_offset)\n",
    "\n",
    "\n",
    "    # Ensure offsets are consistent\n",
    "    if len(ele_offsets) < 9:\n",
    "        raise ValueError(\"ele_offsets must contain at least 9 elements for parsing.\")\n",
    "\n",
    "    # Process the binary data\n",
    "    for i in range(0, len(raw_bytes), ele_offsets[-1]):\n",
    "        try:\n",
    "            new_data = {\n",
    "                \"local0\": struct.unpack(\"f\", raw_bytes[i + ele_offsets[0]: i + ele_offsets[1]])[0],\n",
    "                \"local1\": struct.unpack(\"f\", raw_bytes[i + ele_offsets[1]: i + ele_offsets[2]])[0],\n",
    "                \"var_local0\": struct.unpack(\"f\", raw_bytes[i + ele_offsets[2]: i + ele_offsets[3]])[0],\n",
    "                \"var_local1\": struct.unpack(\"f\", raw_bytes[i + ele_offsets[3]: i + ele_offsets[4]])[0],\n",
    "                \"geometry_id\": struct.unpack(\"Q\", raw_bytes[i + ele_offsets[4]: i + ele_offsets[5]])[0],\n",
    "                \"measurement_id\": struct.unpack(\"Q\", raw_bytes[i + ele_offsets[5]: i + ele_offsets[6]])[0],\n",
    "                \"cluster_link\": struct.unpack(\"Q\", raw_bytes[i + ele_offsets[6]: i + ele_offsets[7]])[0],\n",
    "                \"meas_dim\": struct.unpack(\"I\", raw_bytes[i + ele_offsets[7]: i + ele_offsets[8]])[0],\n",
    "            }\n",
    "            data.append(new_data)\n",
    "        except struct.error as e:\n",
    "            print(f\"Error unpacking at index {i}: {e}\")\n",
    "            break\n",
    "    \n",
    "    # create the dataframe\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Configuration\n",
    "binary_file = \"event000000001-measurements.dat\"\n",
    "start_offset = 8\n",
    "ele_offsets = [0, 4, 8, 12, 16, 24, 32, 40, 44, 64]\n",
    "\n",
    "# Read the binary data into a DataFrame\n",
    "df = read_binary_data(binary_file, start_offset, ele_offsets)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_file = \"measurements.csv\"\n",
    "df.to_csv(csv_file, index=False)\n",
    "\n",
    "print(f\"{binary_file} saved to {csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b372699d-25a8-403e-93e9-95af29074f43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
